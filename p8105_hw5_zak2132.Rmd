---
title: 'P8105 Homework #5'
author: 'Zachary Katz (UNI: zak2132)'
date: "11/20/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load packages
library(tidyverse)
library(viridis)

# Set global options for embedding plots and choosing themes
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r import}
# Import CSV and clean names
homicide_df = read_csv(file = "./Data/homicide-data.csv") %>% 
  janitor::clean_names()

# Obtain head of raw data
head(homicide_df)

# Obtain structure of raw data
str(homicide_df)
```

`homicide_df` is a collection of `r nrow(homicide_df)` observations on `r ncol(homicide_df)` variables from The Washington Post. Each observation represents a criminal homicide (i.e. unique victim). Key variables for each homicide include `reported_date` (reported date of homicide), demographic variables for each victim including first and last name (`victim_first` and `victim_last`, respectively), `victim_race`, `victim_age`, and `victim_sex`, as well as location of homicide in both geographical name (`city` and `state`) and coordinates (`lat` and `long`). `disposition` informs us whether a case remains open or closed, including if an arrest was or wasn't made. Data comes from `r n_distinct(pull(homicide_df, state))` states and covers the period from `r min(pull(homicide_df, reported_date))` to `r max(pull(homicide_df, reported_date))`.

We can also summarize the raw data as follows, finding that 60 homicide observations are missing latitude and longitude coordinates and the 28-state data represents 50 unique cities.

```{r}
summary(homicide_df)

skimr::skim(homicide_df)
```

Let's clean the data a bit, including using appropriate variable types.

```{r clean data}
# Clean the data
homicide_df = homicide_df %>% 
  # Change data types where warranted
  # Not changing date using `lubridate` package because no HW analysis requires date var
  mutate(
    victim_age = as.numeric(victim_age),
    victim_sex = as.factor(victim_sex),
    state = as.factor(state)
  ) %>% 
  # Create `city_state` variable and remove unnecessary variables
  mutate(
    city_state = 
      str_c(city, ", ", state),
    # New column for solved or unsolved comes in handy later
    solved_or_not = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>% 
  select(-city, -state, -disposition)
```

We want to summarize within cities to obtain the total number of homicides, and the number of unsolved homicides (with disposition "Closed without arrest" or "Open/No arrest"). We can do this as follows:

```{r count homicides and unsolved homicides by city}
# Total number of homicides by city
homicide_df_cities = homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(solved_or_not == "unsolved"),
    percent_unsolved = round(unsolved_homicides*100 / total_homicides, 1)
  ) %>% 
  arrange(desc(total_homicides))

homicide_df_cities %>% 
  knitr::kable(
    col.names = c("City/State", "Total Homicides", "Unsolved Homicides", "% Unsolved")
  )
```

Chicago has the most homicides, while Tulsa (AL) has the fewest.

We'd like to obtain the estimated proportion of homicides that are unsolved, first for Baltimore, and then for each city, along with confidence intervals for these estimates.

```{r baltimore only}
# Perform proportion test on Baltimore and save as object
prop_test_baltimore = prop.test(
  homicide_df_cities %>% filter(city_state == "Baltimore, MD") %>% pull(unsolved_homicides),
  homicide_df_cities %>% filter(city_state == "Baltimore, MD") %>% 
    pull(total_homicides)
)

# Apply broom::tidy and pull estimated proportion and confidence intervals
tidy_balt_conf = 
  broom::tidy(prop_test_baltimore) %>% 
  select(estimate, conf.low, conf.high)

# Put into nice table
tidy_balt_conf %>% 
  knitr::kable()
```

Now that we've done it for Baltimore, let's iterate over all cities:

```{r iterate prop test}
# Iterate over cities
tests = homicide_df_cities %>% 
  # Apply prop_tests to each row
  mutate(
    prop_tests = map2(.x = unsolved_homicides, .y = total_homicides, ~prop.test(x = .x, n = .y)),
    # Tidy proportion test results over cities
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
  arrange(desc(estimate))

tests %>% 
  knitr::kable(
    col.names = c("City/State", "Estimated Proportion Unsolved", "CI Lower Bound", "CI Upper Bound")
  )
```

Chicago, IL also has the highest estimated proportion of unsolved murders. New Orleans, LA and Baltimore, MD aren't great either!

Finally, let's create a plot that shows the estimates and CIs for each city, organizing the cities according to the proportion of unsolved homicides.

```{r plot unsolved estimates}
tests %>% 
  # Eliminate extreme outlier
  filter(!city_state == "Tulsa, AL") %>% 
  # Generate percentages from proportions
  mutate(
    estimate = 100*estimate,
    conf.low = 100*conf.low,
    conf.high = 100*conf.high
  ) %>% 
  # Reorder cities by estimated proportion unsolved
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(
    axis.text.x = element_text(angle = 60, vjust = 1.0, hjust = 1)
  ) + 
  labs(
    title = "Estimated Proportion Unsolved Homicides by City",
    x = "City",
    y = "% Estimated Unsolved"
  )
```

## Problem 2

