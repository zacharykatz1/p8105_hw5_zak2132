P8105 Homework \#5
================
Zachary Katz (UNI: zak2132)
11/20/2021

## Problem 1

``` r
# Import CSV and clean names
homicide_df = read_csv(file = "./Data/homicide-data.csv", na = c("", "Unknown")) %>% 
  janitor::clean_names()

# Obtain head of raw data
head(homicide_df)
```

    ## # A tibble: 6 × 12
    ##   uid        reported_date victim_last victim_first victim_race victim_age victim_sex
    ##   <chr>              <dbl> <chr>       <chr>        <chr>            <dbl> <chr>     
    ## 1 Alb-000001      20100504 GARCIA      JUAN         Hispanic            78 Male      
    ## 2 Alb-000002      20100216 MONTOYA     CAMERON      Hispanic            17 Male      
    ## 3 Alb-000003      20100601 SATTERFIELD VIVIANA      White               15 Female    
    ## 4 Alb-000004      20100101 MENDIOLA    CARLOS       Hispanic            32 Male      
    ## 5 Alb-000005      20100102 MULA        VIVIAN       White               72 Female    
    ## 6 Alb-000006      20100126 BOOK        GERALDINE    White               91 Female    
    ## # … with 5 more variables: city <chr>, state <chr>, lat <dbl>, lon <dbl>,
    ## #   disposition <chr>

``` r
# Obtain structure of raw data
str(homicide_df)
```

    ## spec_tbl_df [52,179 × 12] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
    ##  $ uid          : chr [1:52179] "Alb-000001" "Alb-000002" "Alb-000003" "Alb-000004" ...
    ##  $ reported_date: num [1:52179] 20100504 20100216 20100601 20100101 20100102 ...
    ##  $ victim_last  : chr [1:52179] "GARCIA" "MONTOYA" "SATTERFIELD" "MENDIOLA" ...
    ##  $ victim_first : chr [1:52179] "JUAN" "CAMERON" "VIVIANA" "CARLOS" ...
    ##  $ victim_race  : chr [1:52179] "Hispanic" "Hispanic" "White" "Hispanic" ...
    ##  $ victim_age   : num [1:52179] 78 17 15 32 72 91 52 52 56 43 ...
    ##  $ victim_sex   : chr [1:52179] "Male" "Male" "Female" "Male" ...
    ##  $ city         : chr [1:52179] "Albuquerque" "Albuquerque" "Albuquerque" "Albuquerque" ...
    ##  $ state        : chr [1:52179] "NM" "NM" "NM" "NM" ...
    ##  $ lat          : num [1:52179] 35.1 35.1 35.1 35.1 35.1 ...
    ##  $ lon          : num [1:52179] -107 -107 -107 -107 -107 ...
    ##  $ disposition  : chr [1:52179] "Closed without arrest" "Closed by arrest" "Closed without arrest" "Closed by arrest" ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   uid = col_character(),
    ##   ..   reported_date = col_double(),
    ##   ..   victim_last = col_character(),
    ##   ..   victim_first = col_character(),
    ##   ..   victim_race = col_character(),
    ##   ..   victim_age = col_double(),
    ##   ..   victim_sex = col_character(),
    ##   ..   city = col_character(),
    ##   ..   state = col_character(),
    ##   ..   lat = col_double(),
    ##   ..   lon = col_double(),
    ##   ..   disposition = col_character()
    ##   .. )
    ##  - attr(*, "problems")=<externalptr>

`homicide_df` is a collection of 52179 observations on 12 variables from
The Washington Post. Each observation represents a criminal homicide
(i.e. unique victim). Key variables for each homicide include
`reported_date` (reported date of homicide), demographic variables for
each victim including first and last name (`victim_first` and
`victim_last`, respectively), `victim_race`, `victim_age`, and
`victim_sex`, as well as location of homicide in both geographical name
(`city` and `state`) and coordinates (`lat` and `long`). `disposition`
informs us whether a case remains open or closed, including if an arrest
was or wasn’t made. Data comes from 28 states and covers the period from
2.0070101^{7} to 2.015111^{8}.

We can also summarize the raw data as follows, finding that 60 homicide
observations are missing latitude and longitude coordinates and the
28-state data represents 50 unique cities.

``` r
summary(homicide_df)
```

    ##      uid            reported_date       victim_last        victim_first      
    ##  Length:52179       Min.   : 20070101   Length:52179       Length:52179      
    ##  Class :character   1st Qu.: 20100318   Class :character   Class :character  
    ##  Mode  :character   Median : 20121216   Mode  :character   Mode  :character  
    ##                     Mean   : 20130899                                        
    ##                     3rd Qu.: 20150911                                        
    ##                     Max.   :201511105                                        
    ##                                                                              
    ##  victim_race          victim_age     victim_sex            city          
    ##  Length:52179       Min.   :  0.0   Length:52179       Length:52179      
    ##  Class :character   1st Qu.: 22.0   Class :character   Class :character  
    ##  Mode  :character   Median : 28.0   Mode  :character   Mode  :character  
    ##                     Mean   : 31.8                                        
    ##                     3rd Qu.: 40.0                                        
    ##                     Max.   :102.0                                        
    ##                     NA's   :2999                                         
    ##     state                lat             lon          disposition       
    ##  Length:52179       Min.   :25.73   Min.   :-122.51   Length:52179      
    ##  Class :character   1st Qu.:33.77   1st Qu.: -96.00   Class :character  
    ##  Mode  :character   Median :38.52   Median : -87.71   Mode  :character  
    ##                     Mean   :37.03   Mean   : -91.47                     
    ##                     3rd Qu.:40.03   3rd Qu.: -81.76                     
    ##                     Max.   :45.05   Max.   : -71.01                     
    ##                     NA's   :60      NA's   :60

``` r
skimr::skim(homicide_df)
```

|                                                  |              |
|:-------------------------------------------------|:-------------|
| Name                                             | homicide\_df |
| Number of rows                                   | 52179        |
| Number of columns                                | 12           |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |              |
| Column type frequency:                           |              |
| character                                        | 8            |
| numeric                                          | 4            |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |              |
| Group variables                                  | None         |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
|:---------------|-----------:|---------------:|----:|----:|------:|----------:|-----------:|
| uid            |          0 |           1.00 |   9 |  10 |     0 |     52179 |          0 |
| victim\_last   |       5764 |           0.89 |   1 |  20 |     0 |     12686 |          0 |
| victim\_first  |       5762 |           0.89 |   1 |  28 |     0 |     16639 |          0 |
| victim\_race   |       4199 |           0.92 |   5 |   8 |     0 |         5 |          0 |
| victim\_sex    |       4231 |           0.92 |   4 |   6 |     0 |         2 |          0 |
| city           |          0 |           1.00 |   5 |  14 |     0 |        50 |          0 |
| state          |          0 |           1.00 |   2 |   2 |     0 |        28 |          0 |
| disposition    |          0 |           1.00 |  14 |  21 |     0 |         3 |          0 |

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |        mean |         sd |          p0 |         p25 |         p50 |         p75 |          p100 | hist  |
|:---------------|-----------:|---------------:|------------:|-----------:|------------:|------------:|------------:|------------:|--------------:|:------|
| reported\_date |          0 |           1.00 | 20130899.16 | 1123419.63 | 20070101.00 | 20100318.00 | 20121216.00 | 20150911.00 | 201511105\.00 | ▇▁▁▁▁ |
| victim\_age    |       2999 |           0.94 |       31.80 |      14.42 |        0.00 |       22.00 |       28.00 |       40.00 |        102.00 | ▃▇▃▁▁ |
| lat            |         60 |           1.00 |       37.03 |       4.35 |       25.73 |       33.77 |       38.52 |       40.03 |         45.05 | ▁▅▅▇▅ |
| lon            |         60 |           1.00 |      -91.47 |      13.75 |     -122.51 |      -96.00 |      -87.71 |      -81.76 |        -71.01 | ▃▁▃▇▅ |

Let’s clean the data a bit, including using appropriate variable types.

``` r
# Clean the data
homicide_df = homicide_df %>% 
  # Change data types where warranted
  # Not changing date using `lubridate` because no HW analysis requires date var
  mutate(
    victim_sex = as.factor(victim_sex),
    state = as.factor(state)
  ) %>% 
  # Create `city_state` variable and remove unnecessary variables
  mutate(
    city_state = 
      str_c(city, ", ", state),
    # New column for solved or unsolved comes in handy later
    solved_or_not = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>% 
  select(-city, -state, -disposition) %>% 
  # Filter out likely error in data entry
  filter(city_state != "Tulsa, AL")
```

We want to summarize within cities to obtain the total number of
homicides, and the number of unsolved homicides (with disposition
“Closed without arrest” or “Open/No arrest”). We can do this as follows:

``` r
# Total number of homicides by city
homicide_df_cities = homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(solved_or_not == "unsolved"),
    percent_unsolved = round(unsolved_homicides*100 / total_homicides, 1)
  ) %>% 
  arrange(desc(total_homicides))

homicide_df_cities %>% 
  knitr::kable(
    col.names = c("City/State", "Total Homicides", "Unsolved Homicides", "% Unsolved")
  )
```

| City/State         | Total Homicides | Unsolved Homicides | % Unsolved |
|:-------------------|----------------:|-------------------:|-----------:|
| Chicago, IL        |            5535 |               4073 |       73.6 |
| Philadelphia, PA   |            3037 |               1360 |       44.8 |
| Houston, TX        |            2942 |               1493 |       50.7 |
| Baltimore, MD      |            2827 |               1825 |       64.6 |
| Detroit, MI        |            2519 |               1482 |       58.8 |
| Los Angeles, CA    |            2257 |               1106 |       49.0 |
| St. Louis, MO      |            1677 |                905 |       54.0 |
| Dallas, TX         |            1567 |                754 |       48.1 |
| Memphis, TN        |            1514 |                483 |       31.9 |
| New Orleans, LA    |            1434 |                930 |       64.9 |
| Las Vegas, NV      |            1381 |                572 |       41.4 |
| Washington, DC     |            1345 |                589 |       43.8 |
| Indianapolis, IN   |            1322 |                594 |       44.9 |
| Kansas City, MO    |            1190 |                486 |       40.8 |
| Jacksonville, FL   |            1168 |                597 |       51.1 |
| Milwaukee, wI      |            1115 |                403 |       36.1 |
| Columbus, OH       |            1084 |                575 |       53.0 |
| Atlanta, GA        |             973 |                373 |       38.3 |
| Oakland, CA        |             947 |                508 |       53.6 |
| Phoenix, AZ        |             914 |                504 |       55.1 |
| San Antonio, TX    |             833 |                357 |       42.9 |
| Birmingham, AL     |             800 |                347 |       43.4 |
| Nashville, TN      |             767 |                278 |       36.2 |
| Miami, FL          |             744 |                450 |       60.5 |
| Cincinnati, OH     |             694 |                309 |       44.5 |
| Charlotte, NC      |             687 |                206 |       30.0 |
| Oklahoma City, OK  |             672 |                326 |       48.5 |
| San Francisco, CA  |             663 |                336 |       50.7 |
| Pittsburgh, PA     |             631 |                337 |       53.4 |
| New York, NY       |             627 |                243 |       38.8 |
| Boston, MA         |             614 |                310 |       50.5 |
| Tulsa, OK          |             583 |                193 |       33.1 |
| Louisville, KY     |             576 |                261 |       45.3 |
| Fort Worth, TX     |             549 |                255 |       46.4 |
| Buffalo, NY        |             521 |                319 |       61.2 |
| Fresno, CA         |             487 |                169 |       34.7 |
| San Diego, CA      |             461 |                175 |       38.0 |
| Stockton, CA       |             444 |                266 |       59.9 |
| Richmond, VA       |             429 |                113 |       26.3 |
| Baton Rouge, LA    |             424 |                196 |       46.2 |
| Omaha, NE          |             409 |                169 |       41.3 |
| Albuquerque, NM    |             378 |                146 |       38.6 |
| Long Beach, CA     |             378 |                156 |       41.3 |
| Sacramento, CA     |             376 |                139 |       37.0 |
| Minneapolis, MN    |             366 |                187 |       51.1 |
| Denver, CO         |             312 |                169 |       54.2 |
| Durham, NC         |             276 |                101 |       36.6 |
| San Bernardino, CA |             275 |                170 |       61.8 |
| Savannah, GA       |             246 |                115 |       46.7 |
| Tampa, FL          |             208 |                 95 |       45.7 |

Chicago has the most homicides, while Tulsa (AL) has the fewest.

We’d like to obtain the estimated proportion of homicides that are
unsolved, first for Baltimore, and then for each city, along with
confidence intervals for these estimates.

``` r
# Perform proportion test on Baltimore and save as object
prop_test_baltimore = prop.test(
  homicide_df_cities %>% filter(city_state == "Baltimore, MD") %>% pull(unsolved_homicides),
  homicide_df_cities %>% filter(city_state == "Baltimore, MD") %>% 
    pull(total_homicides)
)

# Apply broom::tidy and pull estimated proportion and confidence intervals
tidy_balt_conf = 
  broom::tidy(prop_test_baltimore) %>% 
  select(estimate, conf.low, conf.high)

# Put into nice table
tidy_balt_conf %>% 
  knitr::kable()
```

|  estimate |  conf.low | conf.high |
|----------:|----------:|----------:|
| 0.6455607 | 0.6275625 | 0.6631599 |

Now that we’ve done it for Baltimore, let’s iterate over all cities:

``` r
# Iterate over cities
tests = homicide_df_cities %>% 
  # Apply prop_tests to each row
  mutate(
    prop_tests = map2(.x = unsolved_homicides, .y = total_homicides, ~prop.test(x = .x, n = .y)),
    # Tidy proportion test results over cities
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high) %>% 
  arrange(desc(estimate))

tests %>% 
  knitr::kable(
    col.names = c("City/State", "Estimated Proportion Unsolved", "CI Lower Bound", "CI Upper Bound")
  )
```

| City/State         | Estimated Proportion Unsolved | CI Lower Bound | CI Upper Bound |
|:-------------------|------------------------------:|---------------:|---------------:|
| Chicago, IL        |                     0.7358627 |      0.7239959 |      0.7473998 |
| New Orleans, LA    |                     0.6485356 |      0.6231048 |      0.6731615 |
| Baltimore, MD      |                     0.6455607 |      0.6275625 |      0.6631599 |
| San Bernardino, CA |                     0.6181818 |      0.5576628 |      0.6753422 |
| Buffalo, NY        |                     0.6122841 |      0.5687990 |      0.6540879 |
| Miami, FL          |                     0.6048387 |      0.5685783 |      0.6400015 |
| Stockton, CA       |                     0.5990991 |      0.5517145 |      0.6447418 |
| Detroit, MI        |                     0.5883287 |      0.5687903 |      0.6075953 |
| Phoenix, AZ        |                     0.5514223 |      0.5184825 |      0.5839244 |
| Denver, CO         |                     0.5416667 |      0.4846098 |      0.5976807 |
| St. Louis, MO      |                     0.5396541 |      0.5154369 |      0.5636879 |
| Oakland, CA        |                     0.5364308 |      0.5040588 |      0.5685037 |
| Pittsburgh, PA     |                     0.5340729 |      0.4942706 |      0.5734545 |
| Columbus, OH       |                     0.5304428 |      0.5002167 |      0.5604506 |
| Jacksonville, FL   |                     0.5111301 |      0.4820460 |      0.5401402 |
| Minneapolis, MN    |                     0.5109290 |      0.4585150 |      0.5631099 |
| Houston, TX        |                     0.5074779 |      0.4892447 |      0.5256914 |
| San Francisco, CA  |                     0.5067873 |      0.4680516 |      0.5454433 |
| Boston, MA         |                     0.5048860 |      0.4646219 |      0.5450881 |
| Los Angeles, CA    |                     0.4900310 |      0.4692208 |      0.5108754 |
| Oklahoma City, OK  |                     0.4851190 |      0.4467861 |      0.5236245 |
| Dallas, TX         |                     0.4811742 |      0.4561942 |      0.5062475 |
| Savannah, GA       |                     0.4674797 |      0.4041252 |      0.5318665 |
| Fort Worth, TX     |                     0.4644809 |      0.4222542 |      0.5072119 |
| Baton Rouge, LA    |                     0.4622642 |      0.4141987 |      0.5110240 |
| Tampa, FL          |                     0.4567308 |      0.3881009 |      0.5269851 |
| Louisville, KY     |                     0.4531250 |      0.4120609 |      0.4948235 |
| Indianapolis, IN   |                     0.4493192 |      0.4223156 |      0.4766207 |
| Philadelphia, PA   |                     0.4478103 |      0.4300380 |      0.4657157 |
| Cincinnati, OH     |                     0.4452450 |      0.4079606 |      0.4831439 |
| Washington, DC     |                     0.4379182 |      0.4112495 |      0.4649455 |
| Birmingham, AL     |                     0.4337500 |      0.3991889 |      0.4689557 |
| San Antonio, TX    |                     0.4285714 |      0.3947772 |      0.4630331 |
| Las Vegas, NV      |                     0.4141926 |      0.3881284 |      0.4407395 |
| Omaha, NE          |                     0.4132029 |      0.3653146 |      0.4627477 |
| Long Beach, CA     |                     0.4126984 |      0.3629026 |      0.4642973 |
| Kansas City, MO    |                     0.4084034 |      0.3803996 |      0.4370054 |
| New York, NY       |                     0.3875598 |      0.3494421 |      0.4270755 |
| Albuquerque, NM    |                     0.3862434 |      0.3372604 |      0.4375766 |
| Atlanta, GA        |                     0.3833505 |      0.3528119 |      0.4148219 |
| San Diego, CA      |                     0.3796095 |      0.3354259 |      0.4258315 |
| Sacramento, CA     |                     0.3696809 |      0.3211559 |      0.4209131 |
| Durham, NC         |                     0.3659420 |      0.3095874 |      0.4260936 |
| Nashville, TN      |                     0.3624511 |      0.3285592 |      0.3977401 |
| Milwaukee, wI      |                     0.3614350 |      0.3333172 |      0.3905194 |
| Fresno, CA         |                     0.3470226 |      0.3051013 |      0.3913963 |
| Tulsa, OK          |                     0.3310463 |      0.2932349 |      0.3711192 |
| Memphis, TN        |                     0.3190225 |      0.2957047 |      0.3432691 |
| Charlotte, NC      |                     0.2998544 |      0.2660820 |      0.3358999 |
| Richmond, VA       |                     0.2634033 |      0.2228571 |      0.3082658 |

Chicago, IL also has the highest estimated proportion of unsolved
murders. New Orleans, LA and Baltimore, MD aren’t great either!

Finally, let’s create a plot that shows the estimates and CIs for each
city, organizing the cities according to the proportion of unsolved
homicides.

``` r
tests %>% 
  # Generate percentages from proportions
  mutate(
    estimate = 100*estimate,
    conf.low = 100*conf.low,
    conf.high = 100*conf.high
  ) %>% 
  # Reorder cities by estimated proportion unsolved
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(
    axis.text.x = element_text(angle = 60, vjust = 1.0, hjust = 1)
  ) + 
  labs(
    title = "Estimated Proportion Unsolved Homicides by City",
    x = "City",
    y = "% Estimated Unsolved"
  )
```

<img src="p8105_hw5_zak2132_files/figure-gfm/plot unsolved estimates-1.png" width="90%" />

## Problem 2

We need to read in data from individual participants in our longitudinal
study, with each participant’s data stored in a separate file.

``` r
study_df = tibble(
  # Find list of paths to determine commonalities
  path = list.files("./Data/problem_2_data")
) %>% 
  # Iterate over paths to import data, then bind together
  mutate(
    participant_id = str_remove(path, ".csv"),
    path = str_c("./Data/problem_2_data/", path),
    data = map(path, read_csv),
    data = map(data, bind_rows)
  ) %>% 
  # Glean information from file path name into each row
  separate(participant_id, into = c("arm", "subject_id", sep = "_")) %>% 
  # Rename and factorize variable as needed
  mutate(
    arm = as.factor(
      recode(
        arm,
        "con" = "Control",
        "exp" = "Experimental")
    )
  ) %>% 
  select(-4, -path) %>%
  unnest(data) %>% 
  # Reorder columns to be more suitable (identifiers up front)
  select(subject_id, arm, everything()) %>% 
  # Tidy data by ensuring each row represents an observation
  # Each observation is a study participant's observed data point in a given week
  pivot_longer(
    cols = week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "data_point"
  ) %>% 
  # Make week numeric
  mutate(
    week = as.numeric(week)
  ) 

study_df %>% 
  head() %>% 
  knitr::kable()
```

| subject\_id | arm     | week | data\_point |
|:------------|:--------|-----:|------------:|
| 01          | Control |    1 |        0.20 |
| 01          | Control |    2 |       -1.31 |
| 01          | Control |    3 |        0.66 |
| 01          | Control |    4 |        1.96 |
| 01          | Control |    5 |        0.23 |
| 01          | Control |    6 |        1.09 |

Our data looks nice and tidy! Let’s take a quick look at the structure
and summary:

``` r
str(study_df)
```

    ## tibble [160 × 4] (S3: tbl_df/tbl/data.frame)
    ##  $ subject_id: chr [1:160] "01" "01" "01" "01" ...
    ##  $ arm       : Factor w/ 2 levels "Control","Experimental": 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ week      : num [1:160] 1 2 3 4 5 6 7 8 1 2 ...
    ##  $ data_point: num [1:160] 0.2 -1.31 0.66 1.96 0.23 1.09 0.05 1.94 1.13 -0.88 ...

``` r
summary(study_df)
```

    ##   subject_id                  arm          week        data_point    
    ##  Length:160         Control     :80   Min.   :1.00   Min.   :-2.170  
    ##  Class :character   Experimental:80   1st Qu.:2.75   1st Qu.: 0.760  
    ##  Mode  :character                     Median :4.50   Median : 2.080  
    ##                                       Mean   :4.50   Mean   : 2.330  
    ##                                       3rd Qu.:6.25   3rd Qu.: 3.603  
    ##                                       Max.   :8.00   Max.   : 7.660

In total, there are 160 observations, where each observation represents
a study participant’s observed data value in a given week, and 4
variables, which include `subject_id` (unique identifier for each
participant), `arm` (factor variable for control or experimental),
`week` (week observation was made), and `data_point` (observed value in
study).

We’d like to create a spaghetti plot showing observations on each
subject over time:

``` r
study_df %>% 
  ggplot(
    aes(
      x = week,
      y = data_point,
      # Combine two variables into one factor
      group = interaction(arm, subject_id),
      # Color by treatment arm
      color = arm)
    ) + 
      # Increase transparency for individual lines in spaghetti plot
      geom_line(size = 1, alpha = 0.2) +
      # Add line of best fit for each study arm
      geom_smooth(aes(group = as.factor(arm)), alpha = 1.5, se = FALSE) + 
  labs(
    title = "Observed Data Value Over Time By Participant",
    subtitle = "Colored by Study Arm",
    x = "Week",
    y = "Observed Data Point",
    color = "Study Arm"
  )
```

<img src="p8105_hw5_zak2132_files/figure-gfm/create spaghetti plot-1.png" width="90%" />

In this graph, each translucent line represents one participant’s
recorded observation as it changes longitudinally, while the dark purple
and yellow lines represent estimated conditional means over time for the
control vs. experimental arms. Generally, it appears as though those in
the experimental group see an increased in their observed data point by
the end of eight weeks, whereas those in the control group see a mild
decrease over the same study period.

## Problem 3

First, we want to load the `iris` dataset and introduce missing values
at random in each column.

``` r
# Set seed
set.seed(10)

# Iteratively replace with missing values
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

# Clean var names
iris_with_missing = iris_with_missing %>% 
  janitor::clean_names()
```

For numeric variables, we want to fill in missing values with the mean
of non-missing values, whereas for character variables, we want to fill
in missing values with “virginica.” Let’s write a function that takes a
vector as an argument, replaces missing values according to these rules,
and returns the resulting vector. Then, we can apply it to the columns
of `iris_with_missing` using a map statement.

``` r
# Create function
replace_missing = function(x) {
  
  if (is.numeric(x)) {
    # Replace missing values with mean of non-missing values
    replace_na(x, mean(x, na.rm = TRUE))
  } else if (is.character(x)) {
    replace_na(x, "virginica")
  } else {
    stop("Cannot be computed for non-character, non-numeric variables")
  }
  
}

# Apply it to iris_with_missing, ensuring we return a data frame
iris_replaced_missing = map_df(.x = iris_with_missing, ~replace_missing(.x)) %>% 
  knitr::kable()

# Print result
iris_replaced_missing
```

| sepal\_length | sepal\_width | petal\_length | petal\_width | species    |
|--------------:|-------------:|--------------:|-------------:|:-----------|
|      5.100000 |     3.500000 |      1.400000 |     0.200000 | setosa     |
|      4.900000 |     3.000000 |      1.400000 |     0.200000 | setosa     |
|      4.700000 |     3.200000 |      1.300000 |     0.200000 | setosa     |
|      4.600000 |     3.100000 |      1.500000 |     1.192308 | setosa     |
|      5.000000 |     3.600000 |      1.400000 |     0.200000 | setosa     |
|      5.400000 |     3.900000 |      1.700000 |     0.400000 | setosa     |
|      5.819231 |     3.400000 |      1.400000 |     0.300000 | setosa     |
|      5.000000 |     3.400000 |      1.500000 |     0.200000 | setosa     |
|      4.400000 |     2.900000 |      1.400000 |     0.200000 | setosa     |
|      4.900000 |     3.100000 |      3.765385 |     0.100000 | setosa     |
|      5.400000 |     3.075385 |      1.500000 |     0.200000 | setosa     |
|      4.800000 |     3.400000 |      1.600000 |     0.200000 | setosa     |
|      5.819231 |     3.075385 |      1.400000 |     0.100000 | setosa     |
|      4.300000 |     3.000000 |      3.765385 |     0.100000 | setosa     |
|      5.819231 |     4.000000 |      3.765385 |     0.200000 | setosa     |
|      5.700000 |     4.400000 |      1.500000 |     0.400000 | setosa     |
|      5.400000 |     3.900000 |      1.300000 |     0.400000 | setosa     |
|      5.100000 |     3.500000 |      1.400000 |     1.192308 | setosa     |
|      5.700000 |     3.800000 |      1.700000 |     0.300000 | setosa     |
|      5.100000 |     3.800000 |      1.500000 |     1.192308 | setosa     |
|      5.400000 |     3.400000 |      1.700000 |     0.200000 | setosa     |
|      5.100000 |     3.700000 |      1.500000 |     0.400000 | virginica  |
|      4.600000 |     3.600000 |      1.000000 |     0.200000 | setosa     |
|      5.819231 |     3.300000 |      3.765385 |     0.500000 | setosa     |
|      4.800000 |     3.400000 |      1.900000 |     0.200000 | virginica  |
|      5.000000 |     3.000000 |      3.765385 |     0.200000 | setosa     |
|      5.000000 |     3.400000 |      1.600000 |     0.400000 | virginica  |
|      5.200000 |     3.500000 |      1.500000 |     0.200000 | setosa     |
|      5.819231 |     3.400000 |      1.400000 |     0.200000 | setosa     |
|      4.700000 |     3.200000 |      1.600000 |     0.200000 | setosa     |
|      4.800000 |     3.100000 |      3.765385 |     0.200000 | setosa     |
|      5.400000 |     3.075385 |      1.500000 |     0.400000 | setosa     |
|      5.200000 |     3.075385 |      1.500000 |     0.100000 | setosa     |
|      5.500000 |     4.200000 |      1.400000 |     0.200000 | setosa     |
|      4.900000 |     3.100000 |      3.765385 |     0.200000 | setosa     |
|      5.000000 |     3.200000 |      1.200000 |     0.200000 | setosa     |
|      5.500000 |     3.500000 |      1.300000 |     0.200000 | setosa     |
|      4.900000 |     3.600000 |      1.400000 |     0.100000 | setosa     |
|      4.400000 |     3.000000 |      1.300000 |     1.192308 | setosa     |
|      5.100000 |     3.400000 |      1.500000 |     0.200000 | setosa     |
|      5.000000 |     3.500000 |      1.300000 |     0.300000 | setosa     |
|      4.500000 |     3.075385 |      1.300000 |     1.192308 | virginica  |
|      4.400000 |     3.200000 |      1.300000 |     0.200000 | setosa     |
|      5.000000 |     3.500000 |      1.600000 |     0.600000 | setosa     |
|      5.100000 |     3.800000 |      1.900000 |     0.400000 | setosa     |
|      4.800000 |     3.000000 |      1.400000 |     0.300000 | virginica  |
|      5.100000 |     3.800000 |      1.600000 |     0.200000 | setosa     |
|      4.600000 |     3.200000 |      3.765385 |     0.200000 | setosa     |
|      5.300000 |     3.700000 |      1.500000 |     0.200000 | setosa     |
|      5.000000 |     3.075385 |      1.400000 |     0.200000 | setosa     |
|      7.000000 |     3.075385 |      4.700000 |     1.400000 | virginica  |
|      6.400000 |     3.200000 |      4.500000 |     1.500000 | versicolor |
|      6.900000 |     3.100000 |      4.900000 |     1.500000 | versicolor |
|      5.500000 |     2.300000 |      4.000000 |     1.300000 | versicolor |
|      6.500000 |     2.800000 |      4.600000 |     1.500000 | versicolor |
|      5.700000 |     2.800000 |      4.500000 |     1.300000 | versicolor |
|      6.300000 |     3.300000 |      4.700000 |     1.600000 | virginica  |
|      4.900000 |     2.400000 |      3.765385 |     1.000000 | versicolor |
|      6.600000 |     2.900000 |      4.600000 |     1.300000 | virginica  |
|      5.200000 |     2.700000 |      3.900000 |     1.400000 | versicolor |
|      5.000000 |     2.000000 |      3.765385 |     1.000000 | versicolor |
|      5.900000 |     3.000000 |      4.200000 |     1.500000 | versicolor |
|      6.000000 |     2.200000 |      4.000000 |     1.192308 | versicolor |
|      6.100000 |     2.900000 |      4.700000 |     1.400000 | versicolor |
|      5.600000 |     2.900000 |      3.600000 |     1.300000 | versicolor |
|      6.700000 |     3.100000 |      4.400000 |     1.400000 | versicolor |
|      5.600000 |     3.000000 |      4.500000 |     1.500000 | versicolor |
|      5.800000 |     3.075385 |      4.100000 |     1.000000 | versicolor |
|      6.200000 |     2.200000 |      4.500000 |     1.500000 | versicolor |
|      5.600000 |     2.500000 |      3.900000 |     1.100000 | versicolor |
|      5.900000 |     3.200000 |      4.800000 |     1.800000 | versicolor |
|      5.819231 |     2.800000 |      4.000000 |     1.300000 | virginica  |
|      6.300000 |     2.500000 |      4.900000 |     1.500000 | versicolor |
|      5.819231 |     2.800000 |      3.765385 |     1.200000 | versicolor |
|      6.400000 |     2.900000 |      4.300000 |     1.300000 | versicolor |
|      6.600000 |     3.000000 |      4.400000 |     1.400000 | versicolor |
|      6.800000 |     2.800000 |      4.800000 |     1.400000 | versicolor |
|      6.700000 |     3.075385 |      5.000000 |     1.192308 | versicolor |
|      6.000000 |     3.075385 |      4.500000 |     1.192308 | versicolor |
|      5.700000 |     2.600000 |      3.500000 |     1.000000 | virginica  |
|      5.500000 |     2.400000 |      3.800000 |     1.100000 | versicolor |
|      5.819231 |     2.400000 |      3.700000 |     1.000000 | versicolor |
|      5.800000 |     2.700000 |      3.900000 |     1.200000 | versicolor |
|      6.000000 |     2.700000 |      5.100000 |     1.600000 | versicolor |
|      5.400000 |     3.000000 |      4.500000 |     1.500000 | versicolor |
|      5.819231 |     3.400000 |      4.500000 |     1.600000 | versicolor |
|      6.700000 |     3.100000 |      4.700000 |     1.192308 | versicolor |
|      5.819231 |     3.075385 |      4.400000 |     1.300000 | versicolor |
|      5.600000 |     3.000000 |      3.765385 |     1.192308 | versicolor |
|      5.500000 |     2.500000 |      4.000000 |     1.192308 | versicolor |
|      5.500000 |     3.075385 |      4.400000 |     1.200000 | versicolor |
|      5.819231 |     3.075385 |      4.600000 |     1.192308 | versicolor |
|      5.800000 |     3.075385 |      4.000000 |     1.192308 | versicolor |
|      5.000000 |     2.300000 |      3.300000 |     1.192308 | virginica  |
|      5.819231 |     2.700000 |      4.200000 |     1.300000 | versicolor |
|      5.700000 |     3.000000 |      4.200000 |     1.200000 | versicolor |
|      5.700000 |     2.900000 |      4.200000 |     1.300000 | versicolor |
|      6.200000 |     2.900000 |      4.300000 |     1.300000 | versicolor |
|      5.100000 |     2.500000 |      3.000000 |     1.192308 | versicolor |
|      5.700000 |     2.800000 |      4.100000 |     1.300000 | virginica  |
|      6.300000 |     3.075385 |      3.765385 |     2.500000 | virginica  |
|      5.800000 |     2.700000 |      5.100000 |     1.900000 | virginica  |
|      7.100000 |     3.000000 |      5.900000 |     2.100000 | virginica  |
|      6.300000 |     2.900000 |      5.600000 |     1.800000 | virginica  |
|      6.500000 |     3.075385 |      5.800000 |     2.200000 | virginica  |
|      7.600000 |     3.000000 |      6.600000 |     2.100000 | virginica  |
|      4.900000 |     2.500000 |      4.500000 |     1.700000 | virginica  |
|      7.300000 |     2.900000 |      6.300000 |     1.800000 | virginica  |
|      6.700000 |     3.075385 |      3.765385 |     1.800000 | virginica  |
|      5.819231 |     3.600000 |      3.765385 |     2.500000 | virginica  |
|      6.500000 |     3.200000 |      5.100000 |     2.000000 | virginica  |
|      5.819231 |     2.700000 |      5.300000 |     1.900000 | virginica  |
|      6.800000 |     3.000000 |      5.500000 |     2.100000 | virginica  |
|      5.700000 |     3.075385 |      5.000000 |     2.000000 | virginica  |
|      5.800000 |     2.800000 |      5.100000 |     2.400000 | virginica  |
|      6.400000 |     3.200000 |      5.300000 |     2.300000 | virginica  |
|      6.500000 |     3.000000 |      3.765385 |     1.800000 | virginica  |
|      7.700000 |     3.800000 |      6.700000 |     1.192308 | virginica  |
|      7.700000 |     2.600000 |      6.900000 |     2.300000 | virginica  |
|      6.000000 |     2.200000 |      5.000000 |     1.500000 | virginica  |
|      5.819231 |     3.200000 |      5.700000 |     1.192308 | virginica  |
|      5.600000 |     3.075385 |      4.900000 |     2.000000 | virginica  |
|      7.700000 |     2.800000 |      6.700000 |     2.000000 | virginica  |
|      6.300000 |     2.700000 |      4.900000 |     1.800000 | virginica  |
|      6.700000 |     3.300000 |      5.700000 |     2.100000 | virginica  |
|      7.200000 |     3.200000 |      6.000000 |     1.800000 | virginica  |
|      6.200000 |     2.800000 |      4.800000 |     1.800000 | virginica  |
|      6.100000 |     3.000000 |      4.900000 |     1.800000 | virginica  |
|      6.400000 |     2.800000 |      5.600000 |     2.100000 | virginica  |
|      7.200000 |     3.000000 |      5.800000 |     1.600000 | virginica  |
|      7.400000 |     2.800000 |      6.100000 |     1.192308 | virginica  |
|      7.900000 |     3.800000 |      3.765385 |     2.000000 | virginica  |
|      6.400000 |     2.800000 |      3.765385 |     2.200000 | virginica  |
|      5.819231 |     2.800000 |      5.100000 |     1.500000 | virginica  |
|      6.100000 |     3.075385 |      5.600000 |     1.400000 | virginica  |
|      5.819231 |     3.000000 |      6.100000 |     2.300000 | virginica  |
|      5.819231 |     3.400000 |      5.600000 |     1.192308 | virginica  |
|      6.400000 |     3.100000 |      5.500000 |     1.192308 | virginica  |
|      6.000000 |     3.000000 |      4.800000 |     1.800000 | virginica  |
|      6.900000 |     3.100000 |      5.400000 |     2.100000 | virginica  |
|      6.700000 |     3.100000 |      5.600000 |     2.400000 | virginica  |
|      6.900000 |     3.100000 |      5.100000 |     2.300000 | virginica  |
|      5.819231 |     2.700000 |      5.100000 |     1.900000 | virginica  |
|      6.800000 |     3.200000 |      3.765385 |     2.300000 | virginica  |
|      6.700000 |     3.300000 |      3.765385 |     2.500000 | virginica  |
|      6.700000 |     3.000000 |      5.200000 |     2.300000 | virginica  |
|      6.300000 |     2.500000 |      5.000000 |     1.900000 | virginica  |
|      6.500000 |     3.000000 |      5.200000 |     2.000000 | virginica  |
|      5.819231 |     3.400000 |      5.400000 |     2.300000 | virginica  |
|      5.900000 |     3.000000 |      5.100000 |     1.800000 | virginica  |
